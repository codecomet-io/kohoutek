{"version":3,"file":"model.js","sourceRoot":"/","sources":["data_importer/lib/ts-trace-sdk/model.ts"],"names":[],"mappings":"AAGA,OAAQ,KAAK,EAAE,MAAM,SAAS,CAAA;AAoC9B;;;GAGG;AACH;IAQI;;;;;OAKG;IAEH,cAAY,EAAU,EAAE,IAA6B;QAKrD,sBAAsB;QACtB,YAAO,GAAwC,OAAO,CAAC,QAAQ,CAAA;QAE/D,WAAM,GAiBF;YACA,IAAI,EAAE,EAAE,CAAC,IAAI,EAAE;YACf,IAAI,EAAE,EAAE,CAAC,IAAI,EAAE;YACf,UAAU,EAAE,EAAE,CAAC,UAAU,EAAE;YAC3B,OAAO,EAAE,EAAE,CAAC,OAAO,EAAE;YACrB,IAAI,EAAE,EAAE,CAAC,OAAO,EAAE;YAClB,QAAQ,EAAE,EAAE,CAAC,QAAQ,EAAE;YACvB,OAAO,EAAE,EAAE,CAAC,OAAO,EAAE;YACrB,iBAAiB,EAAE,EAAE,CAAC,iBAAiB,EAAE;YACzC,QAAQ,EAAE,EAAE,CAAC,QAAQ,EAAE;YACvB,OAAO,EAAE,EAAE,CAAC,OAAO,EAAE;YACrB,MAAM,EAAE,EAAE,CAAC,MAAM,EAAE;YACnB,QAAQ,EAAE,EAAE,CAAC,QAAQ,EAAE;YACvB,IAAI,EAAE,EAAE,CAAC,IAAI,EAAE;YACf,MAAM,EAAE,EAAE,CAAC,MAAM,EAAE;YACnB,QAAQ,EAAE,EAAE,CAAC,QAAQ,EAAE;YACvB,OAAO,EAAE,EAAE,CAAC,OAAO,EAAE;SACxB,CAAA;QAED,UAAK,GAAe;YAChB,EAAE,EAAE,UAAU;YACd,IAAI,EAAE,eAAe;SACxB,CAAA;QA9CG,IAAI,CAAC,EAAE,GAAG,EAAE,CAAA;QACZ,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAA;IACxB,CAAC;IA6CL,WAAC;AAAD,CAAC,AA/DD,IA+DC;;AAUD,kCAAkC;AAElC;;;;;;GAMG;AACH,MAAM,CAAN,IAAY,cAUX;AAVD,WAAY,cAAc;IACtB,6CAA6C;IAC7C,qCAAmB,CAAA;IACnB,sFAAsF;IACtF,yCAAuB,CAAA;IACvB,iCAAiC;IACjC,yCAAuB,CAAA;IACvB,8EAA8E;IAC9E,8CAA8C;IAC9C,uCAAqB,CAAA;AACzB,CAAC,EAVW,cAAc,KAAd,cAAc,QAUzB;AAED;;;;;GAKG;AACH,MAAM,CAAN,IAAY,YAMX;AAND,WAAY,YAAY;IACpB,iCAAiB,CAAA;IACjB,mCAAmB,CAAA;IACnB,uCAAuB,CAAA;IACvB,kCAAkB,CAAA;IAClB,mCAAmB,CAAA;AACvB,CAAC,EANW,YAAY,KAAZ,YAAY,QAMvB","sourcesContent":["import {bool, int, uint64} from \"codecomet-js/source/buildkit-port/dependencies/golang/mock.js\";\nimport {digest} from \"codecomet-js/source/buildkit-port/dependencies/opencontainers/go-digest.js\";\nimport {Types} from \"codecomet-js/source/protobuf/types.js\";\nimport  * as os from \"node:os\"\n\n/**\n * IMPORTANT NOTES\n *\n * 1. Timing information are subject to caution:\n * - a certain task may take a largely different amount of time if ran in parallel with tasks that may or may not be cached\n * - a certain task ran on different machines will take vastly different time\n * Clearly we do need node-information per-task:\n * - number of core\n * - cputype\n * - memory\n * - load\n * And we also need parallelisism info, or at the very least, a way to correct the \"weight\" a task based on plan timing info\n *\n * 2. Tasks currently do not have a satisfying identifier information:\n * - \"name\" is purely at the discretion of the user, and can very well be used by different tasks\n * - \"digest\" reflects the task content - as such it will change with even minor changes to the task itself\n * - ideally, we would have a unique identifier mechanism that does not change with task changing but that is also unique\n * across an organization\n *\n * 3. We currently miss any form of:\n * - user information - \"who\" triggered the build?\n * - we do not have information about the context - which Github repository, which commit, where does the plan come from\n */\n\n/*\n * A User represents a GitHub account\n */\nexport type User = {\n    id: string\n    name: string\n    // XXX signatures?\n    // gpg: string\n}\n\n/*\n * A runner is a machine able to run CodeComet pipelines.\n * Right now this is being initialized with details from the machine running this script\n */\nexport class Host {\n    // A unique identifier\n    id: string //  = \"uuid1233445\"\n\n    // Provisional: free form labels\n    metadata: {\n        [key: string]: string\n    }\n    /*= {\n        nickname: \"macRaccoon\",\n        description: \"lalalala\",\n        grouptag: \"red-team\",\n        random: \"joke\"\n    }*/\n\n    constructor(id: string, meta: {[key: string]: string}){\n        this.id = id\n        this.metadata = meta\n    }\n\n    // runtime information\n    runtime: {[key: string]: string | undefined} = process.versions\n\n    system: {\n        arch: string,\n        cpus: any[],\n        endianness: string,\n        freemem: int,\n        home: string,\n        hostname: string,\n        loadavg: number[],\n        networkInterfaces: {[key: string]: any},\n        platform: string,\n        release: string,\n        tmpdir: string,\n        totalmem: number,\n        type: string,\n        uptime: number,\n        userInfo: {[key: string]: any},\n        version: string\n    } = {\n        arch: os.arch(),\n        cpus: os.cpus(),\n        endianness: os.endianness(),\n        freemem: os.freemem(),\n        home: os.homedir(),\n        hostname: os.hostname(),\n        loadavg: os.loadavg(),\n        networkInterfaces: os.networkInterfaces(),\n        platform: os.platform(),\n        release: os.release(),\n        tmpdir: os.tmpdir(),\n        totalmem: os.totalmem(),\n        type: os.type(),\n        uptime: os.uptime(),\n        userInfo: os.userInfo(),\n        version: os.version()\n    }\n\n    owner: User = <User>{\n        id: \"spacedub\",\n        name: \"Space Raccoon\"\n    }\n}\n\nexport type Repository = {\n    commit: string\n    author: string\n    parent: string\n    dirty: bool\n    location: string\n}\n\n// usage: process.resourceUsage(),\n\n/*\n * PipelineStatus represents the completion status of the plan.\n * Possible values are:\n * - errored: an action failed\n * - cancelled: the pipeline was interrupted (by the user, or the process has been otherwise killed)\n * - completed: all actions succesfully returned and the pipeline has completed\n */\nexport enum PipelineStatus {\n    // At least one non optional task errored out\n    Errored = \"Errored\",\n    // The plan was interrupted (user interrupt, crash, network shutdown, poney, whatever)\n    Cancelled = \"Cancelled\",\n    // All tasks returned succesfully\n    Completed = \"Completed\",\n    // All non-optional tasks returned successfully, but some optional ones failed\n    // This is provisional, and not used right now\n    Degraded = \"Degraded\"\n}\n\n/*\n * Represents action statuses\n * - cached: the action was not run, as it has already been in the past and is unmodified\n * - errored: the action ran, but failed\n * - completed: the action ran successfully\n */\nexport enum ActionStatus {\n    Cached = \"cached\",\n    Errored = \"errored\",\n    Completed = \"completed\",\n    NotRan = \"not-ran\",\n    Started = \"started\"\n}\n\n/**\n * A Pipeline represents a DAG of actions that are meant to be ran together in order\n * The object here will hold individual tasks, and also a pre-computed report\n */\nexport type Pipeline = {\n    // The unique, never changing identifier of a pipeline - should be the git source and codecomet plan file\n    id: string\n\n    // User chosen short name for the pipeline. Example: \"My Pipeline for Netlify\"\n    name: string\n\n    // User defined description for the plan. Example: \"This pipeline is doing fancy and boo\"\n    description: string\n\n    // Digest uuid of the run\n    runID: string\n    // This means: when did the first task start?\n    // Starting time\n    started: uint64 //string\n    // time at which the last task that did complete actually finished\n    completed: uint64 // string\n    // See status type\n    status: PipelineStatus\n    // The total number of seconds between the first task starting and the last task finishing\n    runtime: int\n    // actual CPU time\n    machineTime: int\n\n    // Helpers providing high-level data about the tasks\n    tasks: {\n        // Total number of tasks\n        total: int\n        // How many were cached\n        cached: int\n        // How many ran success\n        ran: int\n        // How many ran error\n        errored: int\n        // How many started but got interrupted\n        interrupted: int\n        // How many did not run\n        notRan: int\n    }\n\n    // Repository data\n    repository: Repository\n\n    // Trigger: \"manual\" or pull request identifier\n    trigger: string\n\n    // User or entity that triggered the pipeline\n    actor: User\n\n    // Host executing the pipeline\n    node: Host\n\n    // Digest of all tasks that ran\n    tasksID: digest.Digest[]\n}\n\nexport type TasksPool = {[key: digest.Digest]: ActionInstance}\n\n\n\n\n// A log entry is a timestamp and some content\nexport type LogEntry = {\n    timestamp: int\n    content: string\n}\n\nexport type ActionInstance = {\n    // Unique identifier to the action\n    id:    string\n\n    // User defined name\n    name: string\n\n    // A timestamp in date (string) format for easy consumption within Elastic / Kibana\n    // datestamp:     string\n\n    // Parents actions\n    parents:        digest.Digest[]\n\n    // An action has a digest\n    // It is unique based on the action instance *content* (parents + command)\n    // It MAY appear in unrelated, different plans, that would share the same atomic action\n    // for example, if you use the same docker image as a base, this is the same digest\n    // Henceforth, you can NOT assume that said digests are unique\n    // Examples:\n    // - sha256:b613bcf3ce5197ec6f850a64b523cfbb105165c735f8aee2d9a94db25ee7e8c4\n    digest:        digest.Digest\n\n    // When did it start (is not set if it did not start)\n    started:       uint64 // string\n\n    // When did it end (is not set if it did not complete)\n    completed:     uint64 // string\n\n    // If the task ran, the amount of time it took to run (otherwise 0)\n    runtime: int\n\n    // Was it cached\n    cached:        bool\n    // Did it error, and if yes, with what message\n    error:         string\n    // Aggregate status\n    status:  ActionStatus\n    // This is largely TBD - logs may be really sizable and blow-up elastic limits\n    stdout: string // [] // {[key: int]: string}\n    stderr: string //[] // {[key: int]: string}\n\n    // XXX ignore for now\n    progressGroup: Types.ProgressGroup\n}\n"]}